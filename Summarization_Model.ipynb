{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOfaNlzI3+QzsIT4wu6Rzqm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phuonganh412/summarisation-model/blob/main/Summarization_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Summarization with BART using PyTorch and Hugging Face Transformers\n"
      ],
      "metadata": {
        "id": "f-JckTW_HuvA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Libraries and Dependencies"
      ],
      "metadata": {
        "id": "aWe4E9qKH4-A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2haP3OrA0eOq",
        "outputId": "f4a34c52-c35b-4ea8-9419-9ab3900acc36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (17.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers sentencepiece pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBZD98uW08Qa",
        "outputId": "957c1eb9-64f3-4b1c-8b5b-89ca896a9d68"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch] accelerate==0.20.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUDp_FQ9P6F8",
        "outputId": "37d3d0ee-7bec-4ecd-bf63-d262e29c9712"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: accelerate==0.20.1 in /usr/local/lib/python3.10/dist-packages (0.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.1) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.1) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.1) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.1) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.1) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.17.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.1) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.1) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.1) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate==0.20.1) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate==0.20.1) (17.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate==0.20.1) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate==0.20.1) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "DSI1TPud0g6u"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Set device"
      ],
      "metadata": {
        "id": "pO_XVaEWICN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "Sp1Lmbej0n8p"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Load Data"
      ],
      "metadata": {
        "id": "m8uJK879IEkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset from a CSV file containing 'original_text' and 'summary' columns\n",
        "df = pd.read_csv('sample_data/all_v1.csv')\n",
        "train_texts = df['original_text'].tolist()\n",
        "train_summaries = df['reference_summary'].tolist()\n"
      ],
      "metadata": {
        "id": "NnU_oyjC0r5E"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Split Data"
      ],
      "metadata": {
        "id": "1BH0LjR-IRBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and validation sets\n",
        "train_data, val_data = train_test_split(df, test_size=0.1, random_state=42)\n"
      ],
      "metadata": {
        "id": "CcSnOHSW5KnN"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Define Custom Dataset"
      ],
      "metadata": {
        "id": "Vr4d7fqLIYhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a custom dataset class for text summarization\n",
        "class SummarizationDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_input_length=512, max_output_length=150):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_input_length = max_input_length\n",
        "        self.max_output_length = max_output_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Retrieve original text and corresponding summary\n",
        "        original_text = self.data.iloc[index]['original_text']\n",
        "        summary = self.data.iloc[index]['reference_summary']\n",
        "\n",
        "        # Tokenize the input and output sequences\n",
        "        inputs = self.tokenizer(original_text, max_length=self.max_input_length, return_tensors='pt', truncation=True)\n",
        "        targets = self.tokenizer(summary, max_length=self.max_output_length, return_tensors='pt', truncation=True)\n",
        "\n",
        "        # Padding for variable-length sequences\n",
        "        padding_length = max(self.max_input_length - len(inputs['input_ids'][0]), 0)\n",
        "        inputs['input_ids'] = torch.nn.functional.pad(inputs['input_ids'], (0, padding_length), value=tokenizer.pad_token_id)\n",
        "        inputs['attention_mask'] = torch.nn.functional.pad(inputs['attention_mask'], (0, padding_length), value=0)\n",
        "\n",
        "        padding_length = max(self.max_output_length - len(targets['input_ids'][0]), 0)\n",
        "        targets['input_ids'] = torch.nn.functional.pad(targets['input_ids'], (0, padding_length), value=tokenizer.pad_token_id)\n",
        "\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].squeeze(),\n",
        "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
        "            'labels': targets['input_ids'].squeeze()\n",
        "        }\n"
      ],
      "metadata": {
        "id": "VOcBC4X32aFN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Load BART Tokenizer and Model"
      ],
      "metadata": {
        "id": "MtVx2WYMIgAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the BART tokenizer and model from Hugging Face Transformers\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn').to(device)\n"
      ],
      "metadata": {
        "id": "0dqnNTic2SxK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Create Datasets and Data Loaders"
      ],
      "metadata": {
        "id": "GqWqXyTZImRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets and data loaders for training and validation\n",
        "train_dataset = SummarizationDataset(train_data, tokenizer)\n",
        "val_dataset = SummarizationDataset(val_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)\n"
      ],
      "metadata": {
        "id": "pXTqqGluVao2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Training Parameters"
      ],
      "metadata": {
        "id": "_lTPh0d4Ipdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training parameters\n",
        "epochs = 3\n",
        "learning_rate = 1e-5\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "HVAfPoWY3Ken"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Training Loop"
      ],
      "metadata": {
        "id": "9odgCgMqJSEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop to train the text summarization model\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}', unit='batch'):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass through the model\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backward pass and optimization step\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    print(f'Epoch {epoch + 1}, Loss: {average_loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3puBAmwC39Jc",
        "outputId": "c8df36a4-981d-48bb-d497-8a88ae10d7fc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 201/201 [02:14<00:00,  1.50batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.4555568475628373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 201/201 [02:07<00:00,  1.57batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 0.2852138769789715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 201/201 [02:07<00:00,  1.57batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 0.1866249622804905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Save Trained Model"
      ],
      "metadata": {
        "id": "8afy8jV9JkY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained text summarization model\n",
        "model.save_pretrained('summarization_model')\n",
        "tokenizer.save_pretrained('summarization_model')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GIqRpdU9mCc",
        "outputId": "2e5e82f0-638e-49f6-bb1c-6a473aa7f184"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('summarization_model/tokenizer_config.json',\n",
              " 'summarization_model/special_tokens_map.json',\n",
              " 'summarization_model/vocab.json',\n",
              " 'summarization_model/merges.txt',\n",
              " 'summarization_model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Inference"
      ],
      "metadata": {
        "id": "putKC1dsJz41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference to generate summaries for the validation dataset\n",
        "model.eval()\n",
        "generated_summaries = []\n"
      ],
      "metadata": {
        "id": "zkO75WS18iwH"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference\n",
        "model.eval()\n",
        "generated_summaries = []\n",
        "\n",
        "for batch in tqdm(val_loader, desc='Inference', unit='batch'):\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "    # Generate summaries using the trained model\n",
        "    summary_ids = model.generate(input_ids, attention_mask=attention_mask, max_length=150, num_beams=2, length_penalty=2.0)\n",
        "    summaries = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n",
        "    generated_summaries.extend(summaries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPjDAkrt8sQT",
        "outputId": "5045d88b-6b4d-4a12-e69d-1ed5c682d2db"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference: 100%|██████████| 23/23 [00:34<00:00,  1.51s/batch]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Evaluate the Model"
      ],
      "metadata": {
        "id": "QXQVaKbJKBhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rouge\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTN95_PsNbTQ",
        "outputId": "37e8f6c4-9591-4640-b18f-1f08a0c70484"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "\n",
        "rouge = Rouge()\n",
        "references = val_data['reference_summary'].tolist()\n",
        "scores = rouge.get_scores(generated_summaries, references, avg=True)\n",
        "\n",
        "print(\"ROUGE Scores:\", scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZY1LnenMJDxm",
        "outputId": "90f93d12-e773-46be-c22d-e0c28effccd4"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE Scores: {'rouge-1': {'r': 0.4827886689764848, 'p': 0.21254628859046049, 'f': 0.2785428388827907}, 'rouge-2': {'r': 0.2565510633846612, 'p': 0.08235111170360826, 'f': 0.11482782443106589}, 'rouge-l': {'r': 0.44957968849054586, 'p': 0.19777037585099388, 'f': 0.25940470837828683}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's how to interpret these scores:\n",
        "\n",
        "Recall (r): The fraction of the reference summary that is correctly captured by the generated summary. For example, in ROUGE-1, approximately 49% of the unigrams in the reference summary are also present in the generated summary.\n",
        "\n",
        "Precision (p): The fraction of the generated summary that correctly corresponds to the reference summary. In ROUGE-1, about 22% of the unigrams in the generated summary are also present in the reference summary.\n",
        "\n",
        "F1 Score (f): The harmonic mean of recall and precision. It is a balanced measure that considers both false positives and false negatives.\n",
        "\n",
        "These scores range from 0 to 1, where a higher score indicates a better match between the generated and reference summaries.\n"
      ],
      "metadata": {
        "id": "RShYfKezmYKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Run Demo"
      ],
      "metadata": {
        "id": "1WrAvVs4KIX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model and tokenizer\n",
        "loaded_model = BartForConditionalGeneration.from_pretrained('summarization_model')\n",
        "loaded_tokenizer = BartTokenizer.from_pretrained('summarization_model', model_max_length=512)\n"
      ],
      "metadata": {
        "id": "8L8OnbTjGEuD"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example input text of policy for inference\n",
        "input_text = \"the app permits the purchase of virtual currency virtual money and use of that virtual money to purchase virtual items or services that we expressly make available for use in the app virtual goods. the purchase of virtual money and virtual goods is limited to account holders who are either a 18 years of age or older or b under the age of 18 and have the consent of a parent to make the purchase. parents of children under the age of 18 can consult the ios or google play settings for their app to restrict in app purchases but should also monitor their children s accounts for unexpected activity including the purchase of virtual money or virtual goods. purchases of virtual money and virtual goodsvirtual money is a category of content so the purchase of virtual money grants you only a limited nontransferable non sublicensable revocable license to use such virtual money to access and purchase virtual goods in conjunction with your personal noncommercial use of the services. you acknowledge that you do not acquire any ownership rights in or to the virtual money virtual goods or other content any balance of virtual goods or virtual money does not reflect any stored value. you agree that virtual money and virtual goods have no monetary value and do not constitute actual currency or property of any type. virtual money may be redeemed only for virtual goods and can never be sold transferred or exchanged for real money real goods or real services from us or anyone else. you also agree that you will only obtain virtual money and or virtual goods from us and through means provided by us and not from any third party platform exchange broker or other mechanism unless expressly authorized. once you acquire a license to virtual money or virtual goods you may not trade or transfer the virtual money or virtual goods to another individual or account unless such functionality is provided to you by us by way of a feature or service whether inside the app or through some other method e g our website. we may cancel any virtual money or virtual goods sold transferred or exchanged in violation of these terms. any such sale transfer or exchange or attempt to do so is prohibited and may result in the termination of your account. during the term of your license to your virtual money you have the right to redeem your virtual money for selected virtual goods. if you are the parent and you are accepting these terms on behalf of your child you accept and acknowledge that your child has your consent to exercise this right independently. pricing and availability of virtual money and virtual goods are subject to change without notice. we reserve the right at any time to change and update our pricing and inventory of virtual money and virtual goods. as set forth below all virtual money virtual goods and other content is provided as is without any warranty. you agree that all sales by us to you of virtual money and virtual goods are final and that we will not permit exchanges or refunds for any unused virtual money or virtual goods once the transaction has been made. purchases by end users outside the u s virtual money and virtual goods may only be purchased and held by legal residents of countries where access to and use of the services are permitted. if you live in the european union you have certain rights to withdraw from online purchases. however please note that once you download virtual money from us your right of withdrawal ends. you agree that a purchase of virtual money involves immediate download of such content and b you lose your right of withdrawal once your purchase is complete. if you live in the european union we will provide you with a vat invoice when we are required to do so by law. you agree that these invoices may be electronic in format. we reserve the right to control regulate change or remove any virtual money or virtual goods without any liability to you.\"\n",
        "\n",
        "# Tokenize and generate summary\n",
        "input_ids = loaded_tokenizer(input_text, max_length=512, return_tensors='pt', truncation=True).input_ids\n",
        "attention_mask = loaded_tokenizer(input_text, max_length=512, return_tensors='pt', truncation=True).attention_mask\n",
        "\n",
        "summary_ids = loaded_model.generate(input_ids, attention_mask=attention_mask, max_length=100, num_beams=2, length_penalty=2.0)\n",
        "generated_summary = loaded_tokenizer.decode(summary_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
        "\n",
        "# Print the results\n",
        "print(\"Input Text:\", input_text)\n",
        "print(\"Generated Summary:\", generated_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAKn_fMqQ60Z",
        "outputId": "38f0eef0-0958-41be-f3a2-3d6f27f96434"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text: the app permits the purchase of virtual currency virtual money and use of that virtual money to purchase virtual items or services that we expressly make available for use in the app virtual goods. the purchase of virtual money and virtual goods is limited to account holders who are either a 18 years of age or older or b under the age of 18 and have the consent of a parent to make the purchase. parents of children under the age of 18 can consult the ios or google play settings for their app to restrict in app purchases but should also monitor their children s accounts for unexpected activity including the purchase of virtual money or virtual goods. purchases of virtual money and virtual goodsvirtual money is a category of content so the purchase of virtual money grants you only a limited nontransferable non sublicensable revocable license to use such virtual money to access and purchase virtual goods in conjunction with your personal noncommercial use of the services. you acknowledge that you do not acquire any ownership rights in or to the virtual money virtual goods or other content any balance of virtual goods or virtual money does not reflect any stored value. you agree that virtual money and virtual goods have no monetary value and do not constitute actual currency or property of any type. virtual money may be redeemed only for virtual goods and can never be sold transferred or exchanged for real money real goods or real services from us or anyone else. you also agree that you will only obtain virtual money and or virtual goods from us and through means provided by us and not from any third party platform exchange broker or other mechanism unless expressly authorized. once you acquire a license to virtual money or virtual goods you may not trade or transfer the virtual money or virtual goods to another individual or account unless such functionality is provided to you by us by way of a feature or service whether inside the app or through some other method e g our website. we may cancel any virtual money or virtual goods sold transferred or exchanged in violation of these terms. any such sale transfer or exchange or attempt to do so is prohibited and may result in the termination of your account. during the term of your license to your virtual money you have the right to redeem your virtual money for selected virtual goods. if you are the parent and you are accepting these terms on behalf of your child you accept and acknowledge that your child has your consent to exercise this right independently. pricing and availability of virtual money and virtual goods are subject to change without notice. we reserve the right at any time to change and update our pricing and inventory of virtual money and virtual goods. as set forth below all virtual money virtual goods and other content is provided as is without any warranty. you agree that all sales by us to you of virtual money and virtual goods are final and that we will not permit exchanges or refunds for any unused virtual money or virtual goods once the transaction has been made. purchases by end users outside the u s virtual money and virtual goods may only be purchased and held by legal residents of countries where access to and use of the services are permitted. if you live in the european union you have certain rights to withdraw from online purchases. however please note that once you download virtual money from us your right of withdrawal ends. you agree that a purchase of virtual money involves immediate download of such content and b you lose your right of withdrawal once your purchase is complete. if you live in the european union we will provide you with a vat invoice when we are required to do so by law. you agree that these invoices may be electronic in format. we reserve the right to control regulate change or remove any virtual money or virtual goods without any liability to you.\n",
            "Generated Summary: the app allows you to use virtual currency virtual money to purchase virtual goods. you can only use virtual money for the purposes of the app and not for other purposes. you may only redeem your virtual money once and only for selected virtual goods and you may not transfer it to another person.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HTpPKvP_NdYU"
      },
      "execution_count": 41,
      "outputs": []
    }
  ]
}